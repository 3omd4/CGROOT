# ğŸ§  CGROOT++

<div align="center">

![C++](https://img.shields.io/badge/C++-17-blue.svg?style=for-the-badge&logo=cplusplus)
![CMake](https://img.shields.io/badge/CMake-3.10+-green.svg?style=for-the-badge&logo=cmake)
![Visual Studio](https://img.shields.io/badge/Visual%20Studio-2019-purple.svg?style=for-the-badge&logo=visual-studio)
![License](https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge)

**A High-Performance C++ Deep Learning Framework**

[ğŸš€ Quick Start](#-quick-start) â€¢ [ğŸ“– Documentation](#-documentation) â€¢ [ğŸ”§ Installation](#-installation) â€¢ [ğŸ’¡ Examples](#-examples) â€¢ [ğŸ¤ Contributing](#-contributing)

</div>

---

## ğŸ“‹ Table of Contents

- [ğŸ¯ Overview](#-overview)
- [âœ¨ Features](#-features)
- [ğŸš€ Quick Start](#-quick-start)
- [ğŸ”§ Installation](#-installation)
- [ğŸ“– Documentation](#-documentation)
- [ğŸ’¡ Examples](#-examples)
- [ğŸ—ï¸ Project Structure](#ï¸-project-structure)
- [ğŸ› ï¸ Available Scripts](#ï¸-available-scripts)
- [ğŸ§ª Testing](#-testing)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ“„ License](#-license)

---

## ğŸ¯ Overview

CGROOT++ is a modern, high-performance deep learning framework built from the ground up in C++. Designed for both research and production use, it provides a clean, intuitive API similar to PyTorch while leveraging the speed and efficiency of C++.

### ğŸ¯ Key Goals
- **Performance**: Optimized C++ implementation for maximum speed
- **Simplicity**: Clean, intuitive API design
- **Flexibility**: Modular architecture for easy extension
- **Education**: Clear code structure for learning deep learning internals

---

## âœ¨ Features

### ğŸ§® Core Components
- **ğŸ“Š Tensor Operations**: Multi-dimensional arrays with automatic differentiation
- **ğŸ”„ Automatic Differentiation**: Dynamic computational graph with gradient computation
- **âš¡ CPU Kernels**: Optimized mathematical operations for CPU execution

### ğŸ§  Neural Network Layers
- **ğŸ”— Linear Layer**: Fully connected linear transformations
- **ğŸ”„ ReLU Activation**: Rectified Linear Unit activation function
- **ğŸ“ˆ Sigmoid Activation**: Sigmoid activation function
- **ğŸ—ï¸ Sequential Container**: Stack multiple layers in sequence
- **ğŸ–¼ï¸ Conv2D Layer**: 2D Convolutional layer (planned)

### ğŸ“‰ Loss Functions
- **ğŸ“Š MSE Loss**: Mean Squared Error for regression tasks
- **ğŸ¯ Cross Entropy Loss**: Cross Entropy for classification tasks

### ğŸ›ï¸ Optimizers
- **ğŸ“‰ SGD**: Stochastic Gradient Descent
- **âš¡ Adam**: Adaptive Moment Estimation optimizer

### ğŸ› ï¸ Development Tools
- **ğŸ”§ Interactive Manager**: Windows batch script for easy project management
- **ğŸ§ª Unit Tests**: Comprehensive test suite
- **ğŸ“š Examples**: Ready-to-run example programs

---

## ğŸš€ Quick Start

### ğŸªŸ Windows (Recommended)

**Simply double-click `CGROOT_Manager.bat`** to open the interactive project manager with all available options!

The manager provides:
- ğŸ”¨ **Build Options**: Debug and Release configurations
- â–¶ï¸ **Run Options**: Execute examples and tests
- ğŸ§¹ **Clean Options**: Clean build directories
- ğŸ“Š **Status Check**: View project status and file locations
- ğŸ¯ **VS Integration**: Open Visual Studio solution

### ğŸ§ Linux/macOS

```bash
# Clone the repository
git clone <repository-url>
cd CGROOT

# Create build directory
mkdir build && cd build

# Configure with CMake
cmake ..

# Build the project
make

# Run examples
./bin/cgrunner
./bin/simple_test
```

---

## ğŸ”§ Installation

### Prerequisites

- **C++ Compiler**: C++17 compatible (GCC 7+, Clang 5+, MSVC 2019+)
- **CMake**: Version 3.10 or higher
- **Visual Studio**: 2019 or later (Windows)

### Windows Installation

1. **Install Visual Studio 2019** or later with C++ development tools
2. **Install CMake** (usually included with Visual Studio)
3. **Clone the repository**:
   ```cmd
   git clone <repository-url>
   cd CGROOT
   ```
4. **Run the manager**:
   ```cmd
   CGROOT_Manager.bat
   ```

### Linux Installation

```bash
# Install dependencies (Ubuntu/Debian)
sudo apt update
sudo apt install build-essential cmake git

# Install dependencies (CentOS/RHEL)
sudo yum groupinstall "Development Tools"
sudo yum install cmake git

# Clone and build
git clone <repository-url>
cd CGROOT
mkdir build && cd build
cmake ..
make
```

### macOS Installation

```bash
# Install dependencies with Homebrew
brew install cmake git

# Clone and build
git clone <repository-url>
cd CGROOT
mkdir build && cd build
cmake ..
make
```

---

## ğŸ“– Documentation

### ğŸ—ï¸ Architecture Overview

CGROOT++ follows a modular architecture with clear separation of concerns:

```
src/
â”œâ”€â”€ core/           # Core tensor and parameter classes
â”œâ”€â”€ autograd/       # Automatic differentiation system
â”œâ”€â”€ math/           # Mathematical operations and kernels
â”œâ”€â”€ nn/             # Neural network layers and modules
â””â”€â”€ optim/          # Optimization algorithms
```

### ğŸ”§ API Reference

#### Tensor Operations
```cpp
#include "core/tensor.h"

// Create tensors
auto a = Tensor<float>({2, 3});  // 2x3 tensor
auto b = Tensor<float>({3, 4});  // 3x4 tensor

// Basic operations
auto c = a + b;                  // Element-wise addition
auto d = a.matmul(b);            // Matrix multiplication
auto e = a.relu();               // ReLU activation
```

#### Neural Network Layers
```cpp
#include "nn/linear.h"
#include "nn/relu.h"
#include "nn/sequential.h"

// Create a simple neural network
auto model = Sequential<float>();
model.add(std::make_shared<Linear<float>>(784, 128));
model.add(std::make_shared<ReLU<float>>());
model.add(std::make_shared<Linear<float>>(128, 10));
```

#### Training Loop
```cpp
#include "nn/mse_loss.h"
#include "optim/sgd.h"

// Define loss and optimizer
auto criterion = MSELoss<float>();
auto optimizer = SGD<float>(model.parameters(), 0.01);

// Training loop
for (int epoch = 0; epoch < num_epochs; ++epoch) {
    optimizer.zero_grad();
    auto output = model.forward(input);
    auto loss = criterion.forward(output, target);
    loss.backward();
    optimizer.step();
}
```

---

## ğŸ’¡ Examples

### ğŸ“ Available Examples

| Example | Description | Status |
|---------|-------------|--------|
| `simple_test.cpp` | Basic tensor operations demo | âœ… Ready |
| `xor_solver.cpp` | XOR problem solver with MLP | ğŸš§ In Development |

### ğŸš€ Running Examples

#### Windows
```cmd
# Using the manager
CGROOT_Manager.bat
# Select option 3 or 4 to run examples

# Or manually
.\build\bin\Debug\simple_test.exe
.\build\bin\Debug\cgrunner.exe
```

#### Linux/macOS
```bash
./bin/simple_test
./bin/cgrunner
```

### ğŸ“ Example: Simple Tensor Operations

```cpp
#include <iostream>
#include "core/tensor.h"

int main() {
    // Create tensors
    auto a = Tensor<float>({2, 3}, {1, 2, 3, 4, 5, 6});
    auto b = Tensor<float>({2, 3}, {2, 3, 4, 5, 6, 7});
    
    // Perform operations
    auto c = a + b;
    auto d = a * b;
    
    // Print results
    std::cout << "Tensor a:\n" << a << std::endl;
    std::cout << "Tensor b:\n" << b << std::endl;
    std::cout << "a + b:\n" << c << std::endl;
    std::cout << "a * b:\n" << d << std::endl;
    
    return 0;
}
```

---

## ğŸ—ï¸ Project Structure

```
CGROOT/
â”œâ”€â”€ ğŸ“ src/                    # Source code
â”‚   â”œâ”€â”€ ğŸ“ core/              # Core tensor and parameter classes
â”‚   â”‚   â”œâ”€â”€ tensor.h/cpp      # Main tensor implementation
â”‚   â”‚   â”œâ”€â”€ parameter.h       # Parameter wrapper for learnable weights
â”‚   â”‚   â””â”€â”€ shape.h           # Shape utilities
â”‚   â”œâ”€â”€ ğŸ“ autograd/          # Automatic differentiation
â”‚   â”‚   â”œâ”€â”€ graph.h/cpp       # Computational graph
â”‚   â”‚   â””â”€â”€ op_nodes.h/cpp    # Operation nodes
â”‚   â”œâ”€â”€ ğŸ“ math/              # Mathematical operations
â”‚   â”‚   â””â”€â”€ cpu_kernels.h/cpp # CPU-optimized kernels
â”‚   â”œâ”€â”€ ğŸ“ nn/                # Neural network layers
â”‚   â”‚   â”œâ”€â”€ module.h          # Base module class
â”‚   â”‚   â”œâ”€â”€ linear.h          # Linear layer
â”‚   â”‚   â”œâ”€â”€ relu.h            # ReLU activation
â”‚   â”‚   â”œâ”€â”€ sigmoid.h         # Sigmoid activation
â”‚   â”‚   â”œâ”€â”€ sequential.h      # Sequential container
â”‚   â”‚   â”œâ”€â”€ conv2d.h          # 2D Convolution
â”‚   â”‚   â”œâ”€â”€ mse_loss.h        # MSE loss function
â”‚   â”‚   â””â”€â”€ cross_entropy_loss.h # Cross entropy loss
â”‚   â””â”€â”€ ğŸ“ optim/             # Optimizers
â”‚       â”œâ”€â”€ optimizer.h       # Base optimizer class
â”‚       â”œâ”€â”€ sgd.h             # SGD optimizer
â”‚       â””â”€â”€ adam.h            # Adam optimizer
â”œâ”€â”€ ğŸ“ examples/              # Example programs
â”‚   â”œâ”€â”€ simple_test.cpp       # Basic functionality demo
â”‚   â””â”€â”€ xor_solver.cpp        # XOR problem solver
â”œâ”€â”€ ğŸ“ tests/                 # Unit tests
â”‚   â”œâ”€â”€ test_tensor.cpp       # Tensor operation tests
â”‚   â””â”€â”€ test_autograd.cpp     # Autograd tests
â”œâ”€â”€ ğŸ“ build/                 # Build output directory
â”œâ”€â”€ ğŸ“„ CMakeLists.txt         # CMake configuration
â”œâ”€â”€ ğŸ“„ CGROOT_Manager.bat     # Windows project manager
â””â”€â”€ ğŸ“„ README.md              # This file
```

---

## ğŸ› ï¸ Available Scripts

### ğŸªŸ Windows Scripts

| Script | Description | Usage |
|--------|-------------|-------|
| **`CGROOT_Manager.bat`** | ğŸ¯ Interactive project manager with all features | Double-click or run from command line |
| **`build_debug.bat`** | ğŸ”¨ Build Debug configuration only | `build_debug.bat` |
| **`build_release.bat`** | ğŸ”¨ Build Release configuration only | `build_release.bat` |
| **`run_debug.bat`** | â–¶ï¸ Run Debug executables only | `run_debug.bat` |
| **`run_release.bat`** | â–¶ï¸ Run Release executables only | `run_release.bat` |
| **`build_and_run.bat`** | ğŸ”„ Interactive build and run script | `build_and_run.bat` |

### ğŸ§ Linux/macOS Commands

```bash
# Build commands
make                    # Build all targets
make cgrunner          # Build main executable only
make simple_test       # Build example only

# Run commands
./bin/cgrunner         # Run main executable
./bin/simple_test      # Run example

# Clean commands
make clean             # Clean build files
rm -rf build/          # Remove entire build directory
```

---

## ğŸ§ª Testing

### ğŸ§ª Running Tests

#### Windows
```cmd
# Using the manager
CGROOT_Manager.bat
# Select option 8 to check project status

# Or manually run test executables
.\build\bin\Debug\simple_test.exe
```

#### Linux/macOS
```bash
# Run tests
make test
# Or run individual test executables
./bin/simple_test
```

### ğŸ“‹ Test Coverage

| Component | Test File | Status | Coverage |
|-----------|-----------|--------|----------|
| **Tensor Operations** | `test_tensor.cpp` | ğŸš§ Planned | Basic math operations |
| **Automatic Differentiation** | `test_autograd.cpp` | ğŸš§ Planned | Gradient computation |
| **Neural Network Layers** | Integration tests | ğŸš§ Planned | Forward/backward passes |
| **Optimizers** | Integration tests | ğŸš§ Planned | Parameter updates |

---

## ğŸ¤ Contributing

We welcome contributions to CGROOT++! Here's how you can help:

### ğŸ› Reporting Issues
- Use the GitHub issue tracker
- Provide detailed reproduction steps
- Include system information and error messages

### ğŸ’¡ Suggesting Features
- Open a GitHub issue with the "enhancement" label
- Describe the use case and expected behavior
- Consider contributing the implementation

### ğŸ”§ Development Setup

1. **Fork the repository**
2. **Clone your fork**:
   ```bash
   git clone https://github.com/yourusername/CGROOT.git
   cd CGROOT
   ```
3. **Create a feature branch**:
   ```bash
   git checkout -b feature/your-feature-name
   ```
4. **Make your changes** and test thoroughly
5. **Commit your changes**:
   ```bash
   git commit -m "Add: your feature description"
   ```
6. **Push to your fork**:
   ```bash
   git push origin feature/your-feature-name
   ```
7. **Create a Pull Request**

### ğŸ“‹ Development Guidelines

- **Code Style**: Follow existing code conventions
- **Documentation**: Update README and code comments
- **Testing**: Add tests for new features
- **Performance**: Consider performance implications
- **Compatibility**: Ensure cross-platform compatibility

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **PyTorch** for API design inspiration
- **Eigen** for mathematical operations reference
- **CMake** for cross-platform build system
- **Visual Studio** for excellent C++ development tools

---

<div align="center">

**Made with â¤ï¸ by the CGROOT++ Team**

[â­ Star us on GitHub](https://github.com/yourusername/CGROOT) â€¢ [ğŸ› Report Issues](https://github.com/yourusername/CGROOT/issues) â€¢ [ğŸ’¬ Discussions](https://github.com/yourusername/CGROOT/discussions)

</div>